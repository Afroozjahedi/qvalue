\documentclass{article}

%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{qvalue Package}

\usepackage{graphics}
\usepackage{amsmath}
\usepackage{fullpage}
\usepackage{bibentry}
\usepackage[parfill]{parskip}
\setlength{\parskip}{10pt}
%\usepackage{indentfirst}
\usepackage[colorlinks=true]{hyperref}
\usepackage[utf8]{inputenc}
\nobibliography*


\Sexpr{library(knitr); opts_chunk$set(tidy=TRUE, cache=TRUE, warning=FALSE, message=FALSE,fig.align='center')}

\begin{document}

<<foo,cache=FALSE,include=FALSE,echo=FALSE>>=
library(qvalue)
options(keep.source = TRUE, width = 48)
foo <- packageDescription("qvalue")
@

\title{Bioconductor's {\tt qvalue} package \\ Version \Sexpr{foo$Version}}
\author{John D. Storey and Andrew J. Bass \\ Princeton University \\ \url{http://genomine.org/contact.html}}
\maketitle
\tableofcontents

\section{Introduction}

The {\tt qvalue} package performs false discovery rate (FDR) estimation from a collection of p-values or from a collection of test-statistics with corresponding simulated null statistics. This package produces esitmates of three key quantities: qvalues, $\pi_0$, and local false discovery rates.

When carrying out multiple hypothesis tests, one typically starts either with a set of p-values or with a list of test-statistics.  Either quantity yields a natual ordering of tests from most significant to least significant.  For example, using p-values one would order the tests from smallest p-value (most significant) to largest p-value (least significant).  As another example, using F-statistics one would order the tests from largest F-statistic (most significant) to smallest F-statistic (least significant).

One may then ask: ``If I draw a significance threshold somewhere along this list, how much can I trust the top of the list, i.e., those I choose to call statistically singiciant?''  Another possible question is: ``Where should I draw a line of significance along this list so that we can expect that at most 10\% of the list I call significant is composed of false positives?''  We may also wish to know the reliability of a set of tests called significant for all possible thresholds simultaneously or we may want to estimate the probability that any given test is a true null hypothesis.  

The {\tt qvalue} package forms various estimates that allow one to answer these and other questions.  The quantity of interest is the false discovery rate -- sometimes abbreviated as FDR -- which is roughly defined to be the expected proportion of false discoveries (also known as false positives) among all tests that are called significant.  An overview of the FDR and its well-established methods and theory may be found in Storey (2011) \cite{Storey2011} (also freely available at \url{http://genomine.org/}).


\section{Citing this package}

\bibentry{storey:2002}.

\bibentry{storey:2003}.

\bibentry{storey:tibs:2003}.

\bibentry{storey:etal:2004}.

\bibentry{Storey2011}.

\section{Getting help}
Many questions about {\tt qvalue} will hopefully be answered by the documentation or references.  As with any R package, detailed information on functions, their arguments and values, can be obtained in the help files. To view the
help for {\tt qvalue} within R, type
<<help_qvalue>>=
help(package="qvalue")
@
\noindent If you identify bugs related to basic usage please contact the authors directly.  Otherwise, any questions or problems regarding {\tt qvalue} will most efficiently be addressed on the Bioconductor mailing list, \url{http://stat.ethz.ch/mailman/listinfo/bioconductor}.

\section{Quick start guide}
Given a set of p-values, the q-values can be calculated by using the {\tt qvalue} function:
<<quick_p>>=
data(hedenfalk)
pvalues <- hedenfalk$p
qobj <- qvalue(pvalues)
qvalues <- qobj$qvalues
@

Additionally, q-values can be calculated given a set of observed and null statistics:
<<quick_stat>>=
data(hedenfalk)
obs.stat <- hedenfalk$stat
null.stat <- hedenfalk$stat0
pvalues <- empPvals(stat=obs.stat, stat0=null.stat)
qobj <- qvalue(pvalues)
qvalues <- qobj$qvalues
@
The following sections of the manual go through a case study to show additional features of the {\tt qvalue} package.

\section{Case study: differential gene expression}
We demonstrate the functionality of this package using gene expression data from the breast cancer study of Hedenfalk et al. (2001) \cite{hedenfalk:etal:2001}. The data set is included with the {\tt qvalue} package:

<<load_qvalue>>=
data(hedenfalk)
names(hedenfalk)
@

The data set has three variables: {\tt p}, {\tt stat}, \text{stat0}. The {\tt p} variable contains the p-values of the data set, the {\tt stat} contains the alternative statistics and the {\tt stat0} contains the null statistics.

The comparison was made between two types of genetic mutation that are associated with an increased risk of breast cancer, BRCA1 and BRCA2. There were 7 and 8 cDNA arrays for BRCA1 and BRCA2, respectively. The example considered here is restricted to $3,170$ genes as described in Storey and Tibshirani (2003) \cite{storey:tibs:2003}.\footnote{The original data and code for pre-processing can be found at \url{http://genomine.org/qvalue}.}

\subsection{Checking the p-value histogram}
To get a feel for the data, it is essential to view the p-value histogram:
<<pvalue_hist2, dependson=c("load_qvalue", "quick_p"),  fig.height=4>>=
hist(hedenfalk$p, nclass=20)
@

The p-values are relatively flat at the end of the histogram which is important to determine an accurate $\pi_{0}$ estimate. Suppose the p-value histogram instead looked like

<<pvalue_histBad, dependson=c("load_qvalue", "quick_p"), echo=FALSE, fig.height=4>>=
set.seed(478)
p2 = c(hedenfalk$p, (runif(450, min=0.7, max=1))^(0.33))
somethingWrong = list(p=p2)
hist(somethingWrong$p, nclass=20)
@

The ``U'' shaped p-value histogram is a red flag that something drastically went wrong in the experiment or in the analysis steps. The take-home message is to be very cautious if the p-values do not flatten at the end of the p-value histogram.


\subsection{Calculating q-values}
Once youâ€™ve graphed the p-values and confirmed they are well-behaved, the function {\tt qvalue} can be used to calculate the q-values:

<<run_qvalue, dependson="load_qvalue">>=
qobj <- qvalue(p = hedenfalk$p)
@

Several arguments can be used in the function {\tt qvalue}. The following lists the main arguments:

\begin{itemize}
\item {\tt p}: A vector of p-values. This is the only necessary input.
\item {\tt lambda}: The values of the tuning parameter to be considered in estimating $\pi_0$. These must be in [0,1] and are set to lambda=seq(0, 0.95, 0.05) by default. Optional; see Storey (2002) \cite{storey:2002} for more information.
\item {\tt pi0.method}: Either ``smoother'' or ``bootstrap''; the method for automatically choosing tuning parameter lambda in the estimate of $\pi_0$. If the lambda argument above is only given one value, then this option is ignored. The default option is ``smoother''.
\item {\tt fdr.level}: The level at which to control the false discovery rate. Optional; if this is selected, a vector of TRUE and FALSE is returned in the {\tt fdr.level} slot that specifies whether each q-value is less than fdr.level or not. 
\item {\tt pfdr}: An indicator of whether it is desired to make the estimate more robust  for small p-values. This uses the point estimate of ``positive false discovery rate'' (pFDR). Optional; see Storey (2002) \cite{storey:2002} for more information.
\end{itemize}

The most delicate aspect of this software is choosing how to estimate $\pi_0$ via lambda and pi0.method. If no options are selected, then by default the smoother method (pi0.method$=$``smoother'') proposed in Storey and Tibshirani (2003) \cite{storey:tibs:2003} is used. This is recommended over the bootstrap method, but can backfire for a small number of p-values or in pathological situations. An overall safer option is the bootstrap method (pi0.method$=$``bootstrap'') proposed in Storey, Taylor \& Siegmund (2004) \cite{storey:etal:2004}. 

If one selects lambda=0, then this produces the estimate implicit in the Benjamini and Hochberg (1995) \cite{benjamini:hochberg:1995} methodology. In particular, setting lambda=0 estimates $\pi_0$ to be 1. This can be viewed as a special conservative case of the Storey methodology (2002) \cite{storey:2002}, so at the very least it is recommended using pi0.method$=$``bootstrap'' rather than setting lambda to some predetermined number, such as lambda=0. 

\subsection{The {\tt qvalue} object}
Running the function {\tt qvalue} in the previous section returns a {\tt qvalue} object. A qvalue object can be summarized by using the {\tt summary} function:

<<summary_qvalue, dependson="run_qvalue">>=
summary(qobj)
@

The summary provides a nice way of viewing the $\pi_{0}$ estimate and the number of significant genes at various cutoffs for different metrics. The cutoffs printed in the {\tt summary} function can be controlled by changing the {\tt cuts} argument.

The object contains many important fields:
<<outNames, dependson="run_qvalue">>=
names(qobj)
@
A description of each is described below.
\begin{itemize}
\item {\tt call}: The function call.
\item {\tt pi0}: An estimate of the proportion of null p-values.
\item {\tt qvalues}: A vector of the estimated q-values (the main quantity of interest).
\item {\tt pvalues}: A vector of the original p-values
\item {\tt lfdr}: A vector of the local FDR values. The local FDR values is the FDR value at a given q-value.
\item {\tt significant}: If fdr.level is specified, and indicator of whether the q-value fell below fdr.level (taking all such q-values to be significant controls FDR at level fdr.level).
\item {\tt pi0.lambda}: an estimate of the proportion of null p-values at each lambda from spline fit. If pi0.method is ``bootstrap'' then it returns NULL.
\item {\tt lambda}: A vector lambda values utilized in the spline fit for determining the $\pi_{0}$ value.
\end{itemize}

One very important number that is obtained with the software is an estimate of the overall proportion of true null hypotheses, $\pi_0$:

<<pi0, dependson="run_qvalue">>=
pi0 <- qobj$pi0
@

An estimate of the proportion of non-null tests is one minus this number. This is quite a useful number to know, even if all the truly significant tests cannot all be explicitly identified. 

Another important estimate that is returned is the local FDR:

<<lfdr, dependson="run_qvalue">>=
lfdr <- qobj$lfdr
@

The local FDR gives the local error rate for each observation while the global FDR gives the error rate for a group of observations. From the {\tt summary} output of the {\tt hedenfalk} object, a global FDR cutoff of 10\% determines 319 and 868 significant genes using q-values and p-values, respectively. The local FDR determines 167 significant genes for the same cutoff. Using the local FDR value provides insight to the power of each test. For example, calling a gene that has a p-value of 0.05 significant will be misleading if it has a local FDR value 0.3. 

The p-values, q-values can also be respectively listed by the following commands:


<<getVals, dependson="run_qvalue">>=
pvalues <- qobj$pvalues
qvalues <- qobj$qvalues
@

\subsection{Visualizing results}
The {\tt hist} or {\tt plot} function can be used to visualize the final results. The function {\tt plot} allows one to view several useful plots:
\begin{itemize}
\item The estimated $\pi_{0}$ versus the tuning parameter $\lambda$
\item The q-values versus the p-values
\item The number of significant tests versus each q-value cut-off
\item The number of expected false positives versus the number of significant tests
\end{itemize}

Applying {\tt plot} to the {\tt hedenfalk} qvalue object: 
<<plot_qobj, dependson=c("load_qvalue", "run_qvalue"), fig.height=4>>=
plot(qobj)
@

The main purpose of the first plot is to gauge the reliability of the $\pi_{0}$. Basically, a tuning parameter $\lambda$ has to be chosen to estimate $\pi_{0}$. The variable $\lambda$ is called lambda in the software; it can be fixed or automatically chosen. The estimated $\pi_{0}$ is plotted versus the tuning parameter $\lambda$. As $\lambda$ gets larger, the bias of the estimate decreases, yet the variance increases. See Storey (2002) \cite{storey:2002} for more on this. Comparing your final estimate of $\pi_{0}$ to this plot gives a good sense as to its quality. A smoother is fit to the plot in order to elucidate the trend of the estimates. The remaining plots show how many tests are significant, as well as how many false positives to expect for each q-value cut-off. 


Additionally, running {\tt hist} on a q-value object can be used to view the histogram of p-values along with line plots of both q-values and local FDR values versus the p-values:

<<hist_qobj, dependson=c("load_qvalue", "run_qvalue"), fig.height=4>>=
hist(qobj)
@

\section{Point-and-click implementation}
A \href{http://shiny.rstudio.com}{Shiny} implementation of the package written by Andrew Bass can be found at \url{http://qvalue.princeton.edu}.

\section{Frequently asked questions}

\section*{Acknowledgements}
This software development has been supported in part by funding from the National Institutes of Health and the Office of Naval Research.

\bibliographystyle{acm}
\bibliography{qvaluerefs} 

\end{document}
